{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a31d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bow  Bag of Words  CountVectorizer\n",
    "# 문서를 고정된 길이의 벡터로 변환\n",
    "# 문서 - 단어행렬\n",
    "# 장점 : 간단하고 빠름,\n",
    "# 단점 : 단어순서 손실, 희소성, 의미적 유사성 무시\n",
    "\n",
    "# tf-idf TfidfVectorizer\n",
    "# 모든 문서에서 자주등장하는 단어의 영향을 줄이고 문서 특이 단어를 강조\n",
    "\n",
    "# multinomal Naive Bayes  확률 모델\n",
    "# LogisticRegression : 다중클래스  회귀기반 분류\n",
    "\n",
    "# RidgeClassifer : 회귀 기반 분류 L2규제\n",
    "\n",
    "# N-gram : 단점 차원폭발에 주의 (정규화/차원 축소 고려)\n",
    "\n",
    "# Kolnpy Okt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ad5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# scikit-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#분류모델\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc956d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =  ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "# # data load\n",
    "# newsgroups_train =  fetch_20newsgroups(subset='train'\n",
    "#                     ,remove = ('headers','footers','quotes')\n",
    "#                     ,categories=categories\n",
    "#                    )\n",
    "# newsgroups_test =  fetch_20newsgroups(subset='test'\n",
    "#                     ,remove = ('headers','footers','quotes')\n",
    "#                     ,categories=categories\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4b5da",
   "metadata": {},
   "source": [
    "categories =  ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "- alt.atheism\t무신론, 종교 비판 토론\t종교의 존재, 신의 존재 유무, 종교적 주장 반박, 철학적 논쟁 등\n",
    "- talk.religion.misc\t일반 종교 토론 (기타 잡담 포함)\t기독교, 불교, 이슬람 등 다양한 종교 관련 이야기, 개인 경험, 신념 공유 등\n",
    "- comp.graphics\t컴퓨터 그래픽스, 이미지 처리\t3D 렌더링, 이미지 파일 포맷, 그래픽 소프트웨어 사용법, OpenGL 등 기술 관련 토론\n",
    "- sci.space 우주 과학, 천문학 로켓, NASA, 행성 탐사, 외계 생명 가능성, 우주 물리학 관련 토론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f6476a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "train_path = r'C:\\LLM\\ch05\\20newsbydate\\20news-bydate-train'\n",
    "test_path = r'C:\\LLM\\ch05\\20newsbydate\\20news-bydate-test'\n",
    "newsgroups_train = load_files(train_path,encoding='latin1')\n",
    "newsgroups_test = load_files(test_path,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb86bf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42606dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 제거\n",
    "def filter_categories(dataset, categories):\n",
    "    target_names = dataset.target_names\n",
    "    selected_idx = [ target_names.index(c) for c in categories  ]\n",
    "    #필터링\n",
    "    data_filtered, target_filtered = [], []\n",
    "    for text,label in zip(dataset.data, dataset.target):\n",
    "        if label in selected_idx:\n",
    "            new_label = selected_idx.index(label)  # 라벨 재 정렬\n",
    "            data_filtered.append(text) ; target_filtered.append( new_label  )\n",
    "    return data_filtered,target_filtered,categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d15ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target, target_names = filter_categories(newsgroups_train,categories)\n",
    "test_data, test_target, _ = filter_categories(newsgroups_test,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afcb8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해더 푸터 인용문 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95ca3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # 헤더 제거\n",
    "    text = re.sub(r'^From:.*\\n', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^Subject:.*\\n', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 풋터 제거\n",
    "    text = re.sub(r'\\n--\\n.*$', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # 인용문 제거\n",
    "    text = re.sub(r'(^|\\n)[>|:].*', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5de6c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ clean_text(t) for t in train_data]\n",
    "test_data = [ clean_text(t) for t in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baef20bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2034, 1353, 1353)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_target), len(test_data), len(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff05c2",
   "metadata": {},
   "source": [
    "- 멀티노멀 나이즈베이즈\n",
    "- 문서에 포함된 단어들의 출현 횟수를 기반으로 해서 그 문서가 어떤 주제에 속할지 확률적\n",
    "- 스팸필터링, 뉴스기사 카테고리, 감성분석\n",
    "\n",
    "- 베이즈정리 확률 이론 - 조건부 확률\n",
    "- 단어A가 나왔을때 이 문서가 스팸 B 일 확률은 얼마\n",
    "\n",
    "$P(\\text{스팸} | \\text{단어들}) = \\frac{P(\\text{단어들} | \\text{스팸}) \\cdot P(\\text{스팸})}{P(\\text{단어들})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932262f",
   "metadata": {},
   "source": [
    "- 나이브 Naive  : 순진한 가정\n",
    "    - 가정 : 문서안의 모든 단어는 서로 독립적\n",
    "    - 현실 : 스펨에 자주 나오는 단어들은 서로 독립적이지 않다\n",
    "    - 실제 : 이러한 가정은 계산량을 빠르게 하고 단순하지만 정확도가 어느정도 나온다\n",
    "- 멀티노멀 : 다항 분포\n",
    "    - 의미 : 단어의 출현 횟수를 중요\n",
    "    - 횟수를 세는 멀티노미얼 방식이 NLP 잘 맞는다\n",
    "    - 모델은 단어의 빈도수 통계\n",
    "    - 스펨메일 통계 spem\n",
    "        - free : 150\n",
    "        - money : 100\n",
    "        - viagra : 50\n",
    "        - report : 5\n",
    "    - 정상메일 Ham 통계\n",
    "        - report:80\n",
    "        - metting : 60\n",
    "        - free : 10\n",
    "    - 이러한 통계를 바탕으로 이 카테고리에서 특정 단어가 나올 확률 P('free'|스펨) 을 모두 계산\n",
    "    - \"Free money meeting\"\n",
    "        - 스펨??\n",
    "            - 기본스펨확률 x 스팸일때 free가 나올 확률 x 스팸일때 money 나올 확률 x 스팸일때 meeting 나올 확률\n",
    "        - 정상\n",
    "            - 기본정상확률 x 정상일때...   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7d64ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\playdata2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk tokenizer stemer\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6623521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05bd54ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034, 2000), (1353, 2000))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df : 단어의 빈도가 최소 5개의 문서에 등장  - 노이즈 감소\n",
    "# max_df : 50% 너무흔한 단어는 제거\n",
    "cv = CountVectorizer(max_features=2000,min_df=5, max_df=0.5)\n",
    "x_train_cv = cv.fit_transform(train_data)\n",
    "x_test_cv = cv.transform(test_data)\n",
    "x_train_cv.shape,  x_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "523a608a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'zip', 'zoo', 'zoology'],\n",
       "      shape=(2000,), dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0f4952f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train_cv[0].toarray()[0])[x_train_cv[0].toarray()[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b35735a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9110127826941986 0.8033998521803399\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.75      0.75      0.75       319\n",
      "talk.religion.misc       0.68      0.63      0.65       251\n",
      "     comp.graphics       0.85      0.92      0.88       389\n",
      "         sci.space       0.88      0.84      0.86       394\n",
      "\n",
      "          accuracy                           0.80      1353\n",
      "         macro avg       0.79      0.79      0.79      1353\n",
      "      weighted avg       0.80      0.80      0.80      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BOW 기반 + MNB\n",
    "# 텍스트 분류의 강력한 baseline  희소데이터에 강함\n",
    "# 모델선택\n",
    "nb = MultinomialNB()\n",
    "# 학습용데이터 벡터데이터\n",
    "nb.fit(x_train_cv,train_target)\n",
    "print(nb.score(x_train_cv, train_target)  , nb.score(x_test_cv,test_target))\n",
    "# 분류 리포트\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred_nb = nb.predict(x_test_cv)\n",
    "print( classification_report(test_target,y_pred_nb,target_names=categories)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0da5e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9311701081612586 0.8159645232815964\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF + MNB + LogisticRegression\n",
    "# TF-IDF로 중요단어 강조, 선형모델과 자주사용  BOW 대비 흔한 단어 영향 감소\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "x_train_tfid = tfidf.fit_transform(train_data)\n",
    "x_test_tfid = tfidf.transform(test_data)\n",
    "\n",
    "# NB + tf-idf \n",
    "nb_tfidf  = MultinomialNB()\n",
    "nb_tfidf.fit(x_train_tfid,train_target)\n",
    "print(nb_tfidf.score(x_train_tfid,train_target),  nb_tfidf.score(x_test_tfid, test_target) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd8fd844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698832206515058 0.8894348894348895\n"
     ]
    }
   ],
   "source": [
    "# logistic \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test \\\n",
    "    = train_test_split(x_train_tfid,train_target,test_size=0.2\n",
    "                       ,stratify=train_target,random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(x_train, y_train)\n",
    "print(lr.score(x_train,y_train),  lr.score(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b858130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9330055316533498 0.8722358722358723\n"
     ]
    }
   ],
   "source": [
    "# 과적합 해결을 위한 규제\n",
    "rc = RidgeClassifier(alpha=10)\n",
    "rc.fit(x_train, y_train)\n",
    "print(rc.score(x_train,y_train),  rc.score(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b93a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905961893054702 0.8353808353808354\n"
     ]
    }
   ],
   "source": [
    "# L1 규제   L1 Logistic(Lasso와 유사)\n",
    "# 일부 계수를 0으로 만들어서 특성 선택을 수행.. 중요피처 select 효과\n",
    "l1_lr = LogisticRegression(penalty='l1',max_iter=1000,solver='saga')\n",
    "l1_lr.fit(x_train,y_train)\n",
    "print(l1_lr.score(x_train,y_train),  l1_lr.score(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07046516, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], shape=(1627, 2000))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 트리모델 + tfidf\n",
    "tree = DecisionTreeClassifier()\n",
    "fores = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
