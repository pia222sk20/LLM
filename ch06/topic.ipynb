{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5d7839",
   "metadata": {},
   "source": [
    "##### 토픽 모델링\n",
    "##### LDA  : 문서 컬렉션에서 숨겨진 주제를 찾아내는 생성 모델\n",
    "- document : 여러 topics의 혼합\n",
    "- topic : 여러 word의 분포\n",
    "- word : 특정 topic에서 생성된 단어\n",
    "- 문서들은 topic의 혼합으로 구성\n",
    "    - 뉴스기사\n",
    "        - 70% 정치 20%경제 10%스포츠\n",
    "    - 토픽은 단어 분포을 갖는다\n",
    "        - 정치 {선거:0.2 대통령:0.15 정부:0.1 ...}\n",
    "        - 경제 {주식:0.25, 금리:0.2, 은행:0.15}\n",
    "- 모든 문서를 토픽의 혼합, 토픽별 단어 분포를 랜던하게 초기화\n",
    "    - 과정을 반복하면\n",
    "        - 각 단어가 어떤 토픽에서 나왔느지 추정\n",
    "        - 각 문서의 토픽비율을 업데이트\n",
    "        - 각 토픽의 단어 분포를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac79890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 단어 행렬 : (8, 36)\n",
      "단어목록 : ['nlp라고도' 'python' '강력하고' '기반합니다' '기술은' '기술입니다' '데이터' '딥러닝은' '만들' '매우'\n",
      " '머신러닝' '머신러닝은' '모델은' '모델을' '발전하고' '방법입니다' '배우기' '분석은' '불립니다' '빠르게' '쉬워요'\n",
      " '신경망을' '이용한' '이해할' '인공지능' '인공지능의' '있습니다' '있어요' '자연어처리' '자연어처리는' '텍스트를'\n",
      " '통계학에' '파이썬으로' '프로그래밍은' '학습' '핵심'] 단어목록 개수 : 36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "documents = [\n",
    "    \"Python 프로그래밍은 매우 강력하고 배우기 쉬워요\",\n",
    "    \"머신러닝은 인공지능의 핵심 기술입니다\",\n",
    "    \"자연어처리는 NLP라고도 불립니다\",\n",
    "    \"딥러닝은 신경망을 이용한 학습 방법입니다\",\n",
    "    \"데이터 분석은 통계학에 기반합니다\",\n",
    "    \"파이썬으로 머신러닝 모델을 만들 수 있습니다\",\n",
    "    \"인공지능 기술은 빠르게 발전하고 있습니다\",\n",
    "    \"자연어처리 모델은 텍스트를 이해할 수 있어요\"\n",
    "]\n",
    "# 단어 벡터화\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    max_features=50,\n",
    "    stop_words=['은','는','이','가','을','를','그','그리고'],\n",
    "    min_df=1,\n",
    "    max_df=0.9\n",
    ")\n",
    "doc_term_matrix = cv.fit_transform(documents)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "print(f'문서 단어 행렬 : {doc_term_matrix.shape}')\n",
    "print(f'단어목록 : {feature_names} 단어목록 개수 : {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dabfa760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서-주제 행렬 : (8, 3)\n",
      "첫번째 문서의 주제 분포\n",
      "Topic 0: 0.0481\n",
      "Topic 1: 0.0483\n",
      "Topic 2: 0.9036\n",
      "각 주제별 상위 단어----\n",
      "[topic 0]\n",
      "  기술은 : 1.3185\n",
      "  모델은 : 1.3178\n",
      "  핵심 : 1.3125\n",
      "  인공지능 : 1.3124\n",
      "  기술입니다 : 1.3116\n",
      "\n",
      "[topic 1]\n",
      "  있습니다 : 1.3128\n",
      "  모델을 : 1.3109\n",
      "  데이터 : 1.3104\n",
      "  분석은 : 1.3095\n",
      "  머신러닝 : 1.3091\n",
      "\n",
      "[topic 2]\n",
      "  매우 : 1.3191\n",
      "  강력하고 : 1.3182\n",
      "  python : 1.3135\n",
      "  nlp라고도 : 1.3131\n",
      "  배우기 : 1.3099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA 모델 생성\n",
    "lda_model =  LatentDirichletAllocation(\n",
    "    n_components=3  # 토픽(주제) 개수\n",
    "    ,random_state=42\n",
    "    ,max_iter=20\n",
    "    ,learning_method='online'   # batch (모든데이터를 한번에 다써서 한번학습), online(미니배치)\n",
    ")\n",
    "# 모델 학습\n",
    "lda_output = lda_model.fit_transform(doc_term_matrix)\n",
    "print(f'문서-주제 행렬 : {lda_output.shape}')\n",
    "print(f'첫번째 문서의 주제 분포')\n",
    "print(f'Topic 0: {lda_output[0,0]:.4f}')\n",
    "print(f'Topic 1: {lda_output[0,1]:.4f}')\n",
    "print(f'Topic 2: {lda_output[0,2]:.4f}')\n",
    "\n",
    "# 각 주제별로 상위 단어 출력\n",
    "def display_topic(model, feature_nams, n_top_words = 5):\n",
    "    print(f'각 주제별 상위 단어----')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        # 가장 높은 가중치를 가진 단어의 인덱스 호출\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [ feature_nams[i] for i in top_words_idx]\n",
    "        top_weights = [ topic[i] for i in top_words_idx ]\n",
    "        print(f'[topic {topic_idx}]')\n",
    "        for word,weight in zip(top_words,top_weights):\n",
    "            print(f'  {word} : {weight:.4f}')\n",
    "        print()\n",
    "display_topic(lda_model, feature_names,n_top_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b4871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각문서의 주요 주제------------\n",
      "문서:0 topic: 2 비율 : 0.9036\n",
      "원문 : Python 프로그래밍은 매우 강력하고 배우기 쉬워요\n",
      "\n",
      "문서:1 topic: 0 비율 : 0.8650\n",
      "원문 : 머신러닝은 인공지능의 핵심 기술입니다\n",
      "\n",
      "문서:2 topic: 2 비율 : 0.8312\n",
      "원문 : 자연어처리는 NLP라고도 불립니다\n",
      "\n",
      "문서:3 topic: 2 비율 : 0.8876\n",
      "원문 : 딥러닝은 신경망을 이용한 학습 방법입니다\n",
      "\n",
      "문서:4 topic: 1 비율 : 0.8655\n",
      "원문 : 데이터 분석은 통계학에 기반합니다\n",
      "\n",
      "문서:5 topic: 1 비율 : 0.8867\n",
      "원문 : 파이썬으로 머신러닝 모델을 만들 수 있습니다\n",
      "\n",
      "문서:6 topic: 0 비율 : 0.8855\n",
      "원문 : 인공지능 기술은 빠르게 발전하고 있습니다\n",
      "\n",
      "문서:7 topic: 0 비율 : 0.8876\n",
      "원문 : 자연어처리 모델은 텍스트를 이해할 수 있어요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 문서의 주요 주제\n",
    "print(f'각문서의 주요 주제------------')\n",
    "for doc_idx, doc in enumerate(lda_output):\n",
    "    main_topic = np.argmax(doc)\n",
    "    confidence = doc[main_topic]\n",
    "    print(f'문서:{doc_idx} topic: {main_topic} 비율 : {confidence:.4f}')\n",
    "    print(f'원문 : {documents[doc_idx]}')\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6a7c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sample.csv', <http.client.HTTPMessage at 0x1a2d9dac690>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 청와대 국민청원 데이터로드\n",
    "import os\n",
    "import urllib.request\n",
    "import ssl\n",
    "url = 'https://s3.ap-northeast-2.amazonaws.com/data10902/petition/petition_sampled.csv'\n",
    "\n",
    "# ssl 인증서 무시\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "urllib.request.urlretrieve(url,'./sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e67550de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answered</th>\n",
       "      <th>votes</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>일자리</td>\n",
       "      <td>국토교통부와 한국주택협회가 행한 부당한 행위와 권력남용에 대한 내용을 청원드립니다.</td>\n",
       "      <td>안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>살려주세요..</td>\n",
       "      <td>안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>고등학교 교육 내용 수준을 낮춰주시고 실용적인 내용을 담아주세요!</td>\n",
       "      <td>저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>기타</td>\n",
       "      <td>한국문화에 창조적요소를 심자</td>\n",
       "      <td>안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>외교/통일/국방</td>\n",
       "      <td>다문화정책 및 할랄 인증 제도</td>\n",
       "      <td>대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  ...                                            content\n",
       "0          58  ...  안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...\n",
       "1          63  ...  안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...\n",
       "2         136  ...  저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...\n",
       "3         141  ...  안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...\n",
       "4         148  ...  대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
