{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5d7839",
   "metadata": {},
   "source": [
    "##### 토픽 모델링\n",
    "##### LDA  : 문서 컬렉션에서 숨겨진 주제를 찾아내는 생성 모델\n",
    "- document : 여러 topics의 혼합\n",
    "- topic : 여러 word의 분포\n",
    "- word : 특정 topic에서 생성된 단어\n",
    "- 문서들은 topic의 혼합으로 구성\n",
    "    - 뉴스기사\n",
    "        - 70% 정치 20%경제 10%스포츠\n",
    "    - 토픽은 단어 분포을 갖는다\n",
    "        - 정치 {선거:0.2 대통령:0.15 정부:0.1 ...}\n",
    "        - 경제 {주식:0.25, 금리:0.2, 은행:0.15}\n",
    "- 모든 문서를 토픽의 혼합, 토픽별 단어 분포를 랜던하게 초기화\n",
    "    - 과정을 반복하면\n",
    "        - 각 단어가 어떤 토픽에서 나왔느지 추정\n",
    "        - 각 문서의 토픽비율을 업데이트\n",
    "        - 각 토픽의 단어 분포를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac79890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 단어 행렬 : (8, 36)\n",
      "단어목록 : ['nlp라고도' 'python' '강력하고' '기반합니다' '기술은' '기술입니다' '데이터' '딥러닝은' '만들' '매우'\n",
      " '머신러닝' '머신러닝은' '모델은' '모델을' '발전하고' '방법입니다' '배우기' '분석은' '불립니다' '빠르게' '쉬워요'\n",
      " '신경망을' '이용한' '이해할' '인공지능' '인공지능의' '있습니다' '있어요' '자연어처리' '자연어처리는' '텍스트를'\n",
      " '통계학에' '파이썬으로' '프로그래밍은' '학습' '핵심'] 단어목록 개수 : 36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "documents = [\n",
    "    \"Python 프로그래밍은 매우 강력하고 배우기 쉬워요\",\n",
    "    \"머신러닝은 인공지능의 핵심 기술입니다\",\n",
    "    \"자연어처리는 NLP라고도 불립니다\",\n",
    "    \"딥러닝은 신경망을 이용한 학습 방법입니다\",\n",
    "    \"데이터 분석은 통계학에 기반합니다\",\n",
    "    \"파이썬으로 머신러닝 모델을 만들 수 있습니다\",\n",
    "    \"인공지능 기술은 빠르게 발전하고 있습니다\",\n",
    "    \"자연어처리 모델은 텍스트를 이해할 수 있어요\"\n",
    "]\n",
    "# 단어 벡터화\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    max_features=50,\n",
    "    stop_words=['은','는','이','가','을','를','그','그리고'],\n",
    "    min_df=1,\n",
    "    max_df=0.9\n",
    ")\n",
    "doc_term_matrix = cv.fit_transform(documents)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "print(f'문서 단어 행렬 : {doc_term_matrix.shape}')\n",
    "print(f'단어목록 : {feature_names} 단어목록 개수 : {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dabfa760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서-주제 행렬 : (8, 3)\n",
      "첫번째 문서의 주제 분포\n",
      "Topic 0: 0.0481\n",
      "Topic 1: 0.0483\n",
      "Topic 2: 0.9036\n",
      "각 주제별 상위 단어----\n",
      "[topic 0]\n",
      "  기술은 : 1.3185\n",
      "  모델은 : 1.3178\n",
      "  핵심 : 1.3125\n",
      "  인공지능 : 1.3124\n",
      "  기술입니다 : 1.3116\n",
      "\n",
      "[topic 1]\n",
      "  있습니다 : 1.3128\n",
      "  모델을 : 1.3109\n",
      "  데이터 : 1.3104\n",
      "  분석은 : 1.3095\n",
      "  머신러닝 : 1.3091\n",
      "\n",
      "[topic 2]\n",
      "  매우 : 1.3191\n",
      "  강력하고 : 1.3182\n",
      "  python : 1.3135\n",
      "  nlp라고도 : 1.3131\n",
      "  배우기 : 1.3099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA 모델 생성\n",
    "lda_model =  LatentDirichletAllocation(\n",
    "    n_components=3  # 토픽(주제) 개수\n",
    "    ,random_state=42\n",
    "    ,max_iter=20\n",
    "    ,learning_method='online'   # batch (모든데이터를 한번에 다써서 한번학습), online(미니배치)\n",
    ")\n",
    "# 모델 학습\n",
    "lda_output = lda_model.fit_transform(doc_term_matrix)\n",
    "print(f'문서-주제 행렬 : {lda_output.shape}')\n",
    "print(f'첫번째 문서의 주제 분포')\n",
    "print(f'Topic 0: {lda_output[0,0]:.4f}')\n",
    "print(f'Topic 1: {lda_output[0,1]:.4f}')\n",
    "print(f'Topic 2: {lda_output[0,2]:.4f}')\n",
    "\n",
    "# 각 주제별로 상위 단어 출력\n",
    "def display_topic(model, feature_nams, n_top_words = 5):\n",
    "    print(f'각 주제별 상위 단어----')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        # 가장 높은 가중치를 가진 단어의 인덱스 호출\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [ feature_nams[i] for i in top_words_idx]\n",
    "        top_weights = [ topic[i] for i in top_words_idx ]\n",
    "        print(f'[topic {topic_idx}]')\n",
    "        for word,weight in zip(top_words,top_weights):\n",
    "            print(f'  {word} : {weight:.4f}')\n",
    "        print()\n",
    "display_topic(lda_model, feature_names,n_top_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b4871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각문서의 주요 주제------------\n",
      "문서:0 topic: 2 비율 : 0.9036\n",
      "원문 : Python 프로그래밍은 매우 강력하고 배우기 쉬워요\n",
      "\n",
      "문서:1 topic: 0 비율 : 0.8650\n",
      "원문 : 머신러닝은 인공지능의 핵심 기술입니다\n",
      "\n",
      "문서:2 topic: 2 비율 : 0.8312\n",
      "원문 : 자연어처리는 NLP라고도 불립니다\n",
      "\n",
      "문서:3 topic: 2 비율 : 0.8876\n",
      "원문 : 딥러닝은 신경망을 이용한 학습 방법입니다\n",
      "\n",
      "문서:4 topic: 1 비율 : 0.8655\n",
      "원문 : 데이터 분석은 통계학에 기반합니다\n",
      "\n",
      "문서:5 topic: 1 비율 : 0.8867\n",
      "원문 : 파이썬으로 머신러닝 모델을 만들 수 있습니다\n",
      "\n",
      "문서:6 topic: 0 비율 : 0.8855\n",
      "원문 : 인공지능 기술은 빠르게 발전하고 있습니다\n",
      "\n",
      "문서:7 topic: 0 비율 : 0.8876\n",
      "원문 : 자연어처리 모델은 텍스트를 이해할 수 있어요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 문서의 주요 주제\n",
    "print(f'각문서의 주요 주제------------')\n",
    "for doc_idx, doc in enumerate(lda_output):\n",
    "    main_topic = np.argmax(doc)\n",
    "    confidence = doc[main_topic]\n",
    "    print(f'문서:{doc_idx} topic: {main_topic} 비율 : {confidence:.4f}')\n",
    "    print(f'원문 : {documents[doc_idx]}')\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6a7c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sample.csv', <http.client.HTTPMessage at 0x1a2d9dac690>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 청와대 국민청원 데이터로드\n",
    "import os\n",
    "import urllib.request\n",
    "import ssl\n",
    "url = 'https://s3.ap-northeast-2.amazonaws.com/data10902/petition/petition_sampled.csv'\n",
    "\n",
    "# ssl 인증서 무시\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "urllib.request.urlretrieve(url,'./sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e67550de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answered</th>\n",
       "      <th>votes</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>일자리</td>\n",
       "      <td>국토교통부와 한국주택협회가 행한 부당한 행위와 권력남용에 대한 내용을 청원드립니다.</td>\n",
       "      <td>안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  ...                                            content\n",
       "0          58  ...  안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample.csv\",nrows=1000)  # 실행속도 때문에 1000개만 로드\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ece6975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16f950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countervectoize 형태 : (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "#한국어 전처리\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "# 명사만. 그리고 한글자 이상만\n",
    "def tokenizer(doc):\n",
    "    return [ token for token in okt.nouns(doc) if len(token) > 1  ]\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    max_features=1000,    \n",
    "    min_df=5,\n",
    "    max_df=0.5,\n",
    "    tokenizer=tokenizer    \n",
    ")\n",
    "pet_cv =  cv.fit_transform(df.content)\n",
    "print(f'countervectoize 형태 : {pet_cv.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7383f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89c269cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda 학습시간 : 6.37초\n"
     ]
    }
   ],
   "source": [
    "# LDA  모델 학습\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time\n",
    "# 시간측정\n",
    "start_time = time.time()\n",
    "lda =  LatentDirichletAllocation(n_components=15\n",
    "                          ,n_jobs=-1\n",
    "                          ,random_state=42\n",
    "                          )\n",
    "pet_topics =  lda.fit_transform(pet_cv)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'lda 학습시간 : {elapsed_time:.2f}초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "716835de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 청소년, 폐지, 보호, 소년법, 범죄, 아이, 생각, 처벌, 악용, 사건, 요즘, 피해자, 부산, 폭행, 여중생\n",
      "Topic #1: 아이, 생각, 사람, 저희, 정말, 문제, 지금, 대통령, 나라, 유치원, 마음, 제발, 시간, 우리, 사회\n",
      "Topic #2: 분양, 정부, 아파트, 정책, 대출, 대한민국, 조합원, 조합, 사업, 난임, 규제, 사람, 결혼, 생각, 지금\n",
      "Topic #3: 보험, 민원, 기간, 처리, 조사, 병원, 회사, 입원, 어머니, 대한, 기관, 담당자, 교통사고, 국민, 내용\n",
      "Topic #4: 생각, 의무, 국민, 국방, 협회, 선택, 경우, 차량, 시간, 문제, 감독, 대한민국, 우리나라, 지금, 대한\n",
      "Topic #5: 경찰, 신고, 병원, 국민, 사건, 조직, 대한민국, 주민, 무고, 사람, 범죄, 경찰서, 위해, 사리, 수사\n",
      "Topic #6: 청원, 국민, 생각, 수도, 청와대, 개선, 인터넷, 문제, 제도, 내용, 의견, 동의, 현재, 댓글, 업무\n",
      "Topic #7: 국민, 지역, 우리, 센터, 대통령, 문제, 다른, 대한, 사람, 주민, 공사, 질환, 이상, 건설, 지금\n",
      "Topic #8: 교사, 학교, 교육, 학생, 보육, 시험, 초등, 교실, 임용, 강사, 운영, 지자체, 교대, 아이, 어린이집\n",
      "Topic #9: 질병, 훈련, 국가, 청원, 수행, 관련, 교육, 군대, 병원, 입대, 발생, 사건, 치료, 직무, 해당\n",
      "Topic #10: 여성, 사람, 생각, 회사, 문화, 남성, 기업, 일자리, 지금, 중소기업, 취업, 사회, 정책, 대한민국, 업체\n",
      "Topic #11: 대통령, 북한, 문재인, 러시아, 정부, 한국, 협력, 미국, 문제, 중국, 한반도, 관계, 전쟁, 사업, 대화\n",
      "Topic #12: 생각, 사건, 처벌, 피해자, 가해자, 폭행, 사람, 여중생, 인권, 범죄, 청소년, 부산, 국민, 학생, 보호\n",
      "Topic #13: 건강, 보험, 소득, 보험료, 근로자, 사업, 기준, 주택, 의료, 제도, 국민, 치료, 부과, 대한, 적용\n",
      "Topic #14: 학교, 학교폭력, 사건, 대한, 학생, 피해, 헌법, 발생, 경찰, 위반, 버스, 법률, 조사, 주장, 수사\n"
     ]
    }
   ],
   "source": [
    "# 토픽단어 출력함수\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx}: \", end='')\n",
    "        top_indices = topic.argsort()[:-n_top_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        print(\", \".join(top_words))\n",
    "feature_names = cv.get_feature_names_out()\n",
    "print_top_words(lda, feature_names,15)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07d535af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Topic12</th>\n",
       "      <th>Topic13</th>\n",
       "      <th>Topic14</th>\n",
       "      <th>Topic15</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.387556</td>\n",
       "      <td>0.357923</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.047502</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.203639</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>2017-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.281660</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.142792</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.448869</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.118051</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>2017-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.662621</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.318939</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>2017-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic1    Topic2    Topic3  ...   Topic14   Topic15   period\n",
       "0  0.000307  0.000307  0.000307  ...  0.203639  0.000307  2017-08\n",
       "1  0.000784  0.281660  0.000784  ...  0.000784  0.000784  2017-08\n",
       "2  0.001418  0.001418  0.001418  ...  0.001418  0.001418  2017-08\n",
       "\n",
       "[3 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토픽 트랜드 분석\n",
    "# 시간 정보 추출\n",
    "df['period'] = pd.to_datetime(df['start']).dt.strftime('%Y-%m')\n",
    "# 토픽 데이터 프레임\n",
    "topic_columns = [f'Topic{i+1}' for i in range(15)]\n",
    "trend_data = pd.DataFrame(pet_topics,columns=topic_columns)\n",
    "trend_data['period'] = df['period'].values\n",
    "trend_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b70b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "기간별 토픽 분포:\n",
      "           Topic1    Topic2    Topic3  ...   Topic13   Topic14   Topic15\n",
      "period                                 ...                              \n",
      "2017-08  0.006378  0.115700  0.070034  ...  0.035617  0.030627  0.014577\n",
      "2017-09  0.308259  0.089161  0.036404  ...  0.156610  0.028752  0.026388\n",
      "2017-10  0.002247  0.121927  0.010279  ...  0.018342  0.207412  0.082638\n",
      "\n",
      "[3 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# 기간별 평균 토픽 가중치 계산\n",
    "trend = trend_data.groupby('period').mean()\n",
    "\n",
    "print(\"\\n기간별 토픽 분포:\")\n",
    "print(trend.head())\n",
    "\n",
    "# 시간 트렌드 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, axes = plt.subplots(5, 3, figsize=(15, 12))\n",
    "fig.suptitle('시간에 따른 토픽 트렌드', fontsize=16)\n",
    "\n",
    "# x축을 datetime으로 변환\n",
    "trend.index = pd.to_datetime(trend.index)\n",
    "trend_sorted = trend.sort_index()\n",
    "\n",
    "for idx, (ax, topic) in enumerate(zip(axes.flat, topic_columns)):\n",
    "    ax.plot(trend_sorted.index, trend_sorted[topic], marker='o')\n",
    "    ax.set_title(topic)\n",
    "    ax.set_ylabel('평균 가중치')\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0665a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
